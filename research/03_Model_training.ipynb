{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Kidney-Disease-Cassification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Kidney-Disease-Cassification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epoch: int  \n",
    "    params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-17 15:08:31,442: WARNING: module_wrapper: From C:\\Users\\Adil\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "]\n",
      "[2023-12-17 15:08:36,428: INFO: utils: NumExpr defaulting to 4 threads.]\n"
     ]
    }
   ],
   "source": [
    "from CNN_Classifier.constants import *\n",
    "from CNN_Classifier.utils.common import read_yaml,create_directories\n",
    "import tensorflow as tf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_fiepath = PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath) \n",
    "        self.params = read_yaml(params_fiepath) \n",
    "    \n",
    "    def get_training_path(self) -> TrainingConfig:\n",
    "        training = self.config.training    \n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir,\"CT_KINDEY_DATASET\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ]) \n",
    "        \n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path = Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epoch=params.EPOCHS,  \n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )  \n",
    "        \n",
    "        return training_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request \n",
    "from zipfile import ZipFile \n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "        self.model.summary()\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale=1.0 / 255.0,\n",
    "            validation_split=0.1\n",
    "        )\n",
    "        self.callback = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0.0001,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            mode=\"auto\",\n",
    "            baseline=None,\n",
    "            restore_best_weights=False\n",
    "        )\n",
    " \n",
    "        self.train_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            image_size=self.config.params_image_size[:-1], \n",
    "            validation_split=0.1,\n",
    "            subset=\"training\",\n",
    "            seed=123,\n",
    "            label_mode='categorical'\n",
    "        )\n",
    "\n",
    "        self.valid_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            image_size=self.config.params_image_size[:-1], \n",
    "            validation_split=0.2,\n",
    "            subset=\"validation\",\n",
    "            seed=123,\n",
    "            label_mode='categorical'\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epoch,\n",
    "            validation_data=self.valid_generator,\n",
    "            callbacks=self.callback\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-17 15:08:46,634: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-17 15:08:46,639: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-17 15:08:46,642: INFO: common: created directory at: artifacts\\training]\n",
      "[2023-12-17 15:08:47,489: WARNING: module_wrapper: From C:\\Users\\Adil\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "]\n",
      "[2023-12-17 15:08:47,650: WARNING: module_wrapper: From C:\\Users\\Adil\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 512)               0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14981444 (57.15 MB)\n",
      "Trainable params: 265732 (1.01 MB)\n",
      "Non-trainable params: 14715712 (56.14 MB)\n",
      "_________________________________________________________________\n",
      "Found 12446 files belonging to 4 classes.\n",
      "Using 11202 files for training.\n",
      "Found 12446 files belonging to 4 classes.\n",
      "Using 2489 files for validation.\n",
      "Epoch 1/10\n",
      "[2023-12-17 15:08:54,632: WARNING: module_wrapper: From C:\\Users\\Adil\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "]\n",
      "351/351 [==============================] - 1535s 4s/step - loss: 1.0026 - accuracy: 0.6352 - val_loss: 0.3360 - val_accuracy: 0.8879\n",
      "Epoch 2/10\n",
      "351/351 [==============================] - 1535s 4s/step - loss: 0.4563 - accuracy: 0.8321 - val_loss: 0.1822 - val_accuracy: 0.9506\n",
      "Epoch 3/10\n",
      "351/351 [==============================] - 1524s 4s/step - loss: 0.2875 - accuracy: 0.8963 - val_loss: 0.1252 - val_accuracy: 0.9642\n",
      "Epoch 4/10\n",
      "351/351 [==============================] - 1524s 4s/step - loss: 0.2246 - accuracy: 0.9220 - val_loss: 0.0832 - val_accuracy: 0.9843\n",
      "Epoch 5/10\n",
      "351/351 [==============================] - 1537s 4s/step - loss: 0.1624 - accuracy: 0.9442 - val_loss: 0.0609 - val_accuracy: 0.9892\n",
      "Epoch 6/10\n",
      "351/351 [==============================] - 1650s 5s/step - loss: 0.1379 - accuracy: 0.9559 - val_loss: 0.0472 - val_accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "351/351 [==============================] - 1697s 5s/step - loss: 0.1116 - accuracy: 0.9635 - val_loss: 0.0380 - val_accuracy: 0.9912\n",
      "Epoch 8/10\n",
      "351/351 [==============================] - 1566s 4s/step - loss: 0.0872 - accuracy: 0.9731 - val_loss: 0.0278 - val_accuracy: 0.9944\n",
      "Epoch 9/10\n",
      "351/351 [==============================] - 1587s 5s/step - loss: 0.0719 - accuracy: 0.9783 - val_loss: 0.0242 - val_accuracy: 0.9952\n",
      "Epoch 10/10\n",
      "351/351 [==============================] - 1631s 5s/step - loss: 0.0666 - accuracy: 0.9796 - val_loss: 0.0179 - val_accuracy: 0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adil\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_path()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()  \n",
    "except Exception as e:\n",
    "    raise e     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
